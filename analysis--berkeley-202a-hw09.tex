\section*{Math 202A - HW9 - Dan Davison - \texttt{ddavison@berkeley.edu}}

% In Bass 8.5, most of you guessed the counterexample f(x)=−(xlogx)−1 or some similar variant. To motivate this
% counterexample, note that x↦x−1 is not integrable near 0 but x↦x−1+ε is. You want something which is not
% integrable, but which is "weakly integrable" (in the sense that it satisfies the conclusion of Bass 8.4). So
% the natural thing to do is search for functions whose growth rate is between x−1 and x−1+ε near the origin,
% which is what this counterexample gives.

% However, when it came time to actually integrate f, a lot of you struggled, and came up with complicated
% solutions. The good news, that some of you picked up on, is Theorem 9.1 in Bass: the Lebesgue and Riemann
% integrals agree whenever both exist. A short proof of this for f: since we're taking an improper Riemann
% integral, we can restrict to the domain I=[δ,1] and take δ→0. Since the Riemann integral exists (since f is
% continuous on the compact set I) it is equal to the limit of lower Riemann sums ∫fη as the mesh |η| of a
% partition η tends to 0. But fη→f pointwise, since fη was sampled from a continuous function (so if |η| is small
% then |f−fη| is also small; this is a typical epsilon-delta argument). But f was Lebesgue integrable on I and
% dominated the fη, so that implies that ∫fη→∫f.

% Another issue here is that some folks recognized that integrating f amounts to computing the Riemann integral,
% but then fumbled on computing the antiderivative. It is not F(x)=loglogx as you might naively expect, since F
% blows up at 1 and is ill-defined (complex-valued and depends on a choice of branch) on [0,1). This can be fixed
% with some calculus, however.

% As for Bass 10.2, let me emphasize that convergence in the metric d that we introduced is not equivalent to
% convergence almost everywhere. It is true that convergence almost everywhere implies convergence in measure
% (hence in the metric d), and convergence in measure (hence in the metric d) implies convergence almost
% everywhere along a subsequence, but the typewriter sequence is a counterexample that prevents us from promoting
% this convergence on a subsequence to convergence almost everywhere.



% 8.5. I don't think this works (I don't even see why that would make the integral diverge). The motivation here
% is the condition here *almost* holds for 1/x, if we were to just perturb it slightly -- so the correct answer
% is something like -1/x log x. (-8)

% Aidan Backus , Nov 14 at 9:57am 10.2. Small nitpick on the triangle inequality -- you definitely want < rather
% than \leq.

% Much more egregiously, convergence in measure is not equivalent to convergence a.e. Since \mu(X) < \infty,
% convergence a.e. implies convergence in measure, but you can only get the converse along a subsequence (the
% counterexample is a typewriter sequence). (-4)

\begin{mdframed}
\includegraphics[width=400pt]{img/analysis--berkeley-202a-hw09-210c.png}
\end{mdframed}

\begin{proof}
  Let $t_1, t_2, \ldots \in \R$ with $\limn t_n = \infty$ and define $A_n = \{x ~:~ f(x) > t_n\}$.

  Thus we have $\lim_{t\to\infty} t ~ \mu\big(\{x ~:~ f(x) \geq t\}\big) = \limn t_n \mu(A_n)$, since the limit
  is the same along any sequence.

  Note that $f\ind_{A_n} \to 0$, since $A_n \downarrow \emptyset$, and note also that $f\ind_{A_n} \leq f$ for
  all $n$.

  Therefore
  \begin{align*}
    \limn t_n \mu(A_n)
    &\leq \limn \int f\ind_{A_n} \\
    &= \int \limn f\ind_{A_n}             &\text{by the dominated convergence theorem}\\
    &= \int \limn 0 \\
    &= 0.
  \end{align*}
\end{proof}

\newpage
\begin{mdframed}
\includegraphics[width=400pt]{img/analysis--berkeley-202a-hw09-b0e8.png}
\end{mdframed}

\begin{proof}
  My original thought was to take the graph of $y = x^{-1/2}$ and place a copy of it over every rational,
  scaled to fit in $\eps/2^k$ where $k$ indexes an enumeration of the rationals, somehow stitching them
  together. However, while something like that might make the integral diverge, I actually don't think it
  solves the limit requirement, and may well not make sense and indeed I haven't accomplished it.
\end{proof}
\newpage

\begin{mdframed}
\includegraphics[width=400pt]{img/analysis--berkeley-202a-hw09-113a.png}
\end{mdframed}

\begin{proof}

  [Incomplete]

  Let $g: [0, 1] \to \R$ be a function that is not constant a.e.

  We will construct an $f$ such that $\int_0^1 f = 0$ and $\int_0^1 fg \neq 0$, thus proving the result by
  contradiction.

  Let $f(x) = x - 1/2$. Note that $\int_0^1 f = 0$.

  If $\int_0^1 fg \neq 0$ then we are done.

  Alternatively, we have $\int_0^1 fg = 0$, or equivalently
  \begin{align*}
    \int_0^{1/2} fg + \int_{1/2}^1 fg = 0.
  \end{align*}

  I feel that it should be possible to solve the problem by contradiction like this: i.e. by specifying a
  procedure that modifies $f$ to produce an $f^*$ such that $\int_0^1 f^*g \neq 0$, while preserving the property that $\int_0^1 f^* = 0$. In particular I note that we
  are free to cut out two vertical strips of the graph of $f$ and exchange them: this will preserve the value
  of the integral.

  Unfortunately I failed to complete the question again despite thinking about it for ages :) I'm including a
  few more of the incomplete approaches to this problem that I thought about below.
\end{proof}


\begin{proof}

  [another incomplete thought]

  We have that for every continuous function $f$ with $\int_0^1 f = 0$ then $\int_0^1 fg = 0$.

  It follows that for every continuous function $f$ with $\int_0^1 f = 0$ and for all $a, b \in \R$
  \begin{align*}
    \int_0^1 af + bfg = 0.
  \end{align*}
  It is given that $g$ is bounded, and we see that $f$ is bounded also since it is continuous on a compact set.

\end{proof}


\begin{proof}

  [another incomplete thought]

  Let $\ms F = \{f: [0, 1] \to \R ~:~ f \text{~is continuous}, \int_0^1 f(x) \dx = 0 \}$.

  Is $\ms F$ (in an appropriate sense) full rank, such that if a function $g$ is orthogonal to every element
  of $f$ then $g$ must be the zero function? (And then some argument allowing $g$ to be any constant a.e.
  function).
\end{proof}


% \begin{proof}
%   Let $f_1 \neq f_2$ be continuous with $\int_0^1 f_1 = \int_0^1 f_2 = 0$.

%   We have that
%   \begin{align*}
%     \int_0^1 f_1g = \int_0^1 f_2g = 0.
%   \end{align*}

%   For example, let $f_n(x) = n(x - 1/2)$. Then
%   \begin{align*}
%     \int_0^1 f_n(x) \dx = n\int_0^1 x \dx - \frac{n}{2} = \frac{n}{2} - \frac{n}{2} = 0.
%   \end{align*}
%   Let
%   \begin{align*}
%     g(x) =
%     \begin{cases}
%       -c & x \leq 1/2 \\
%       +c  & x > 1/2.
%   \end{cases}
%   \end{align*}
%   Then
%   \begin{align*}
%     \int_0^1 f_n(x) g(x)
%     = -cn\int_0^{1/2}(x - 1/2) \dx + cn\int_{1/2}^1(x - 1/2) \dx
%     = 0.
%   \end{align*}
% \end{proof}








% \begin{remark}
%   As a sanity check note that the required behavior with continuous $f$ does obtain
%   \begin{enumerate}
%   \item if $g$ is equal to a constant a.e.: if $c \in \R$ and $g = c$ a.e. then $\int_0^1 f g = c \int_0^1 f = 0$,
%   \item if $f = 0$.
%   \end{enumerate}
% \end{remark}


\begin{proof}

  [another incomplete thought]

  Suppose $g: [0, 1] \to [0, \infty]$ is bounded and measurable.

  Let $\lambda(E) = \int_E g(x) \dx$ for a Borel set $E \subseteq [0, 1]$.

  Then by HW7 Ex. 1 we have that $\lambda$ is a measure on $[0, 1]$ and
  \begin{align*}
    \int_0^1 f(x)g(x) \dx = \int_0^1 f \d\lambda.
  \end{align*}
  Thus the question is equivalent to positing the existence of a measure $\lambda$ such that for every
  continuous function $f$ with $\int_0^1 f(x) \dx = 0$ we have
  \begin{align*}
    \int_0^1 f \d\lambda = 0.
  \end{align*}
\end{proof}






% Suppose condition A(f, g) is true whenever f satisfies condition B. Prove that g satisfies condition C.

% Claim: If (f satisfies condition B) => A(f, g), then g satisfies condition C.

% Proof:

% We must show

% (1) if not B(f) then C(g)

% (2) if B(f) and


% \begin{claim*}
%   Suppose $g: [0, 1] \to \R$ is bounded and measurable.

%   Suppose further that, if $f$ is continuous and $\int_0^1 f = 0$, then
%   \begin{align*}
%     \int_0^1 f g = 0.
%   \end{align*}

%   Prove that $g$ is equal to a constant a.e.
% \end{claim*}

% \begin{intuition}
%   We have an unknown function $g: [0, 1] \to \R$.

%   We are told that whenever $g$ is integrated against a continuous function $f$ for which $\int_0^1 f = 0$, the
%   result is zero.

%   We must prove that $g$ is equal to a constant a.e.


% \end{intuition}

% \begin{proof}
%   Suppose $g$ is not equal to a constant a.e.

% \end{proof}


\newpage
\begin{mdframed}
\includegraphics[width=400pt]{img/analysis--berkeley-202a-hw09-955c.png}
\end{mdframed}

\begin{claim*}
  Henstock-Kurzweil $\int \ind_\Q \neq 0$
\end{claim*}

\begin{proof}

  [There is something wrong with my argument as it basically proves that $\int \ind_\Q \neq 0$]

  We claim that $\int \ind_\Q = 0$.

  Let $\eps > 0$.

  We must prove that there exists a gauge $\delta$ such that for all tagged partitions $(d, p)$ if $(d, p)$
  is $\delta$-fine then
  \begin{align*}
    \sum_{i=1}^n (d_i - d_{i-1})\ind_\Q(p_i) < \eps.
  \end{align*}

  Equivalently we must prove that there exists a gauge $\delta$ such that
  \begin{align*}
    \max_{(d, p) \delta\text{-fine}} \Bigg( \sum_{\{i ~:~ i \in \{1, \ldots, n\}, p_i \in \Q\}} (d_i - d_{i-1}) \Bigg) < \eps,
  \end{align*}

  where we were able to remove the absolute value operator because the $d_i$ are increasing.

  Note that the tagged partition that maximises this quantity will be one for which $p_i \in \Q$ for
  all $i \in \{1, \ldots, n\}$.

  Therefore we must prove that there exists a gauge $\delta$ such that
  \begin{align*}
    \max_{(d, p) \delta\text{-fine}, ~\forall i ~ p_i \in \Q} \sum_{i=1}^n (d_i - d_{i-1}) < \eps,
  \end{align*}
  Note that if $(d, p)$ is a tagged partition such that $p_i \notin \Q$ for all $i \in \{1, \ldots, n\}$, then
  the condition is true. Therefore we need only consider tagged partitions for which some $p_i$ are rational.

  In fact it seems to me that we need to show it's true for tagged partitions for which all $p_i$ are rational,
  since this will maximises the sum. However, in that case we will simply have
  \begin{align*}
    \sum_{i=1}^n (d_i - d_{i-1}) = 1.
  \end{align*}

  \red{TODO} I'm confused about how I'm misunderstanding the definition. I can see solutions to this problem online,
  such as \url{https://www.math.unm.edu/~crisp/courses/math402/spring15/HKintegralStevenJocelyn.pdf}, which I studied but my confusion remained (the
  presentation there is very similar to here).
\end{proof}










% \begin{proof}
%   \begin{align*}
%     \hline
%     &\forall \eps > 0 ~~ \exists \delta ~~ \forall (d, p) ~~ \delta\text{-fine}(d, p) ~~ \Big|\sum_{\{i ~:~ i \in \{1, \ldots, n\}, p_i \in \Q\}} (d_i - d_{i-1})\Big| < \eps
%   \end{align*}

% \begin{align*}
%   &\eps > 0 \\
%   \hline
%   &\exists \delta ~~ \forall (d, p) ~~ \delta\text{-fine}(d, p) ~~ \Big|\sum_{\{i ~:~ i \in \{1, \ldots, n\}, p_i \in \Q\}} (d_i - d_{i-1})\Big| < \eps
%   \end{align*}
% \end{proof}

\newpage
\begin{mdframed}
\includegraphics[width=400pt]{img/analysis--berkeley-202a-hw09-b4e1.png}
\end{mdframed}

\begin{claim*}
  $d$ is a metric on the space of measurable functions except for the fact that $d(f, g) = 0$ implies $f = g$
  a.e., not necessarily everywhere.
\end{claim*}

\begin{proof}~\\
  \begin{enumerate}
  \item {\bf identity of indiscernibles}\\
    Note that $\frac{|f - g|}{1 + |f - g|} \geq 0$. Therefore
    if $d(f, g) = \int\frac{|f - g|}{1 + |f - g|} = 0$ then $|f - g| = 0$ a.e., and therefore $f = g$ a.e.

    Conversely, if $f = g$ a.e. then $|f - g| = 0$ a.e. and we have $d(f, g) = 0$.

  \item {\bf symmetry}\\
    $d(f, g) = \int \frac{|f - g|}{1 + |f - g|} = \int \frac{|g - f|}{1 + |g - f|} = d(g, f)$

  \item {\bf triangle inequality}
    \begin{align*}
      d(f, h)
      &= \int \frac{|f - h|}{1 + |f - h|} \\
      &= \int \frac{|f - g + g - h|}{1 + |f - g + g - h|} \\
      &\leq \int \frac{|f - g| + |g - h|}{1 + |f - g| + |g - h|} \\
      &< \int \frac{|f - g|}{1 + |f - g|} + \int \frac{|g - h|}{1 + |g - h|} \\
      &= d(f, g) + d(g, h)
    \end{align*}
  \end{enumerate}
\end{proof}

\begin{lemma}\label{10-2-lemma}
  $d(f_n, f) \to 0$ if and only if $f_n \to f$ a.e.
\end{lemma}

\begin{proof}
  Since $0 \leq \frac{|f_n - f|}{1 + |f_n - f|} \leq 1$ we may appply the dominated convergence theorem,
  yielding
  \begin{align}
    \limn d(f_n, f)
    &= \limn \int \frac{|f_n - f|}{1 + |f_n - f|} \nonumber\\
    &= \int \limn \frac{|f_n - f|}{1 + |f_n - f|} \nonumber\\
    &= \int \frac{\limn |f_n - f|}{1 + \limn |f_n - f|}. \label{10-2-eqn}
  \end{align}
  First suppose that $d(f_n, f) \to 0$. Then, since for all $n$ the integrand on the RHS of \eqref{10-2-eqn} is
  non-negative, and the denominator of the integrand on the RHS of \eqref{10-2-eqn} is strictly positive, we
  have $\limn |f_n - f| = 0$ a.e. or in other words $f_n \to f$ a.e.

  Converself, suppose that $f_n \to f$ a.e. Then the integrand on the RHS of \eqref{10-2-eqn} is zero and we
  have $d(f_n, f) \to 0$.
\end{proof}


\begin{claim*}
 If $d(f_n, f) \to 0$ then $f_n \to f$ in measure.
\end{claim*}

\begin{proof}
  From lemma \ref{10-2-lemma} we have $f_n \to f$ a.e. Therefore $f_n \to f$ in measure.
\end{proof}

\begin{claim*}
  If $f_n \to f$ in measure then $d(f_n, f) \to 0$.
\end{claim*}

\begin{proof}
  Suppose that $f_n \to f$ in measure.

  Let $\eps > 0$ and define $A_{\eps, n} = \{x ~:~ |f_n(x) - f| > \eps\}$.

  Since $0 \leq \ind_{A_{\eps, n}} \leq 1$ and $\int 1 = \mu(X) < \infty$ we may apply the dominated
  convergence theorem, yielding
  \begin{align*}
    0 = \limn \mu(A_{\eps, n}) = \limn \int \ind_{A_{\eps, n}} = \int \limn \ind_{A_{\eps, n}}.
  \end{align*}
  Since the integrand $\limn \ind_{A_{\eps, n}}$ is non-negative we have
  \begin{align*}
    \limn \ind_{A_{\eps, n}}(x) = 0 \ae,
  \end{align*}
  or equivalently
  \begin{align*}
    \limn |f_n(x) - f(x)| \leq \eps \ae
  \end{align*}
  Thus since $\eps$ was arbitrary we have
  \begin{align*}
    \limn |f_n(x) - f(x)| = 0 \ae
  \end{align*}
  and therefore
  $f_n \to f$ a.e.

  The claim then follows from lemma \ref{10-2-lemma}.
\end{proof}


\newpage
\begin{mdframed}
\includegraphics[width=400pt]{img/analysis--berkeley-202a-hw09-ea17.png}
\end{mdframed}

\begin{proof}
  It suffices to show that the sequence $f_n$ is Cauchy a.e.

  The condition for $f_n(x)$ not Cauchy is that there exists $\eps$ such that for all $N$ there
  exists $m, n \geq N$ such that $|f_m(x) - f_n(x)| \geq \eps$.

  Equivalently, there exists $\eps$ such that for all $N$ there exists $n \geq N$ such
  that $\origsup_{m \geq n} |f_m(x) - f_n(x))| \geq \eps$.

  Let $E_{n, a} = \{x ~:~ \origsup_{m \geq n} |f_m(x) - f_n(x)| \geq a\}$.

  Then the condition for $f_n(x)$ not Cauchy is that there exists $\eps$ such that for all $N$ there
  exists $n \geq N$ such that $x \in E_{n, \eps}$.

  Let $F = \bigcup_{\eps > 0} \bigcap_{N=1}^\infty \bigcup_{n \geq N} E_{n, \eps}$.

  Then if $x \in F$ then $f_n(x)$ is not Cauchy.

  We want to show that $\mu(F) = 0$.

  Since $g_n$ converges in measure to $0$ we have by definition that for all $\eps > 0$
  \begin{align*}
    \limn \mu(E_{n, \eps}) = 0.
  \end{align*}
  Equivalently for all $\eps > 0$ and $\eta > 0$ there exists $N$ such that $\mu(E_{n, \eps}) < \eta$ for
  all $n \geq N$.

  [Argh! I thought I'd be able to finish this one properly but it looks like I'm getting tired and running out
  of time. The remainder of this proof is just a vague sketch of where I was trying to go.]

  Note that $E_{n, \eps}$ includes (a) points $x$ at which the sequence $\(|f_m(x) - f_n(x)|\)_{m=n}^\infty$
  exceeds $\eps$ in supremum finitely many times only and (b) points $x$ at which it never stops
  exceeding $\eps$ in supremum. Let's denote category (b) as $E^*_{n, \eps}$. This set contains the $x$ at
  which $\(f_n(x)\)_{n=1}^\infty$ is not Cauchy.

  Since $E^*_{n, \eps} \subseteq E_{n, \eps}$ we have $\mu(E^*_{n, \eps}) < \eta$, but $\eta$ was arbitrary hence $\mu(E^*_{n, \eps}) = 0$.

  I was hoping to formally link $E^*_{n, \eps}$ with the set $F$ defined above.

  I'm also kind of concerned that there's a factor-of-two argument that I haven't used yet:
  if $\origsup_{m\geq n} |f_m(x) - f_n(x)| < \eps$, then for independent pairs $j, k \geq n$ we
  have $|f_j(x) - f_k(x)| < 2\eps$.
\end{proof}
